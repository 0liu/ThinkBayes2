{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Approximate Bayesian Computation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "Think Bayes, Second Edition\n",
    "\n",
    "Copyright 2020 Allen B. Downey\n",
    "\n",
    "License: [Attribution-NonCommercial-ShareAlike 4.0 International (CC BY-NC-SA 4.0)](https://creativecommons.org/licenses/by-nc-sa/4.0/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# If we're running on Colab, install libraries\n",
    "\n",
    "import sys\n",
    "IN_COLAB = 'google.colab' in sys.modules\n",
    "\n",
    "if IN_COLAB:\n",
    "    !pip install empiricaldist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Get utils.py\n",
    "\n",
    "import os\n",
    "\n",
    "if not os.path.exists('utils.py'):\n",
    "    !wget https://github.com/AllenDowney/ThinkBayes2/raw/master/soln/utils.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from utils import set_pyplot_params\n",
    "set_pyplot_params()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This chapter introduces a method of last resort for the most complex problems, Approximate Bayesian Computation (ABC).\n",
    "I say it is a last resort because it usually requires more computation than other methods, so if you can solve a problem any other way, you should.\n",
    "\n",
    "However, for the examples in this chapter, ABC is not just easy to implement; it is also efficient.\n",
    "\n",
    "The first example is my solution to a problem posed by a patient\n",
    "with a kidney tumor.\n",
    "I use data from a medical journal to model tumor growth, and use simulations to estimate the age of a tumor based on its size.\n",
    "\n",
    "The second example is a model of cell counting, which has applications in biology, medicine, and zymurgy (beer-making).\n",
    "Given a cell count from a diluted sample, we estimate the concentration of cells.\n",
    "\n",
    "Finally, as an exercise, you'll have a chance to work on a fun sock-counting problem.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The Kidney Tumor Problem\n",
    "\n",
    "I am a frequent reader and occasional contributor to the online\n",
    "statistics forum at <http://reddit.com/r/statistics>. \n",
    "In November 2011, I read the following message:\n",
    "\n",
    "> \"I have Stage IV Kidney Cancer and am trying to determine if the cancer formed before I retired from the military. ... Given the dates of retirement and detection is it possible to determine when there was a 50/50 chance that I developed the disease? Is it possible to determine the probability on the retirement date? My tumor was 15.5 cm x 15 cm at detection. Grade II.\"\n",
    "\n",
    "I contacted the author of the message to get more information; I\n",
    "learned that veterans get different benefits if it is \"more likely than not\" that a tumor formed while they were in military service (among other considerations).\n",
    "\n",
    "Because renal tumors grow slowly, and often do not cause symptoms, they are sometimes left untreated. As a result, doctors can observe the rate of growth for untreated tumors by comparing scans from the same patient at different times. Several papers have reported these growth rates.\n",
    "\n",
    "For my analysis I used data from a paper by [Zhang et al](https://pubs.rsna.org/doi/full/10.1148/radiol.2501071712). \n",
    "They report growth rates in two forms:\n",
    "\n",
    "* Volumetric doubling time, which is the time it would take for a tumor to double in size.\n",
    "\n",
    "* Reciprocal doubling time (RDT), which is the number of doublings per year.\n",
    "\n",
    "The next section shows how we work with these growth rates."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "Zhang et al, Distribution of Renal Tumor Growth Rates Determined\n",
    "    by Using Serial Volumetric CT Measurements, January 2009\n",
    "    *Radiology*, 250, 137-144.\n",
    "    \n",
    "https://pubs.rsna.org/doi/full/10.1148/radiol.2501071712"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A Growth Model\n",
    "\n",
    "We'll start with a simple model of tumor growth and gradually add complications.\n",
    "\n",
    "For the simple model, we'll assume\n",
    "\n",
    "* Tumors grow with a constant doubling time, and \n",
    "\n",
    "* They are roughly spherical in shape.\n",
    "\n",
    "And I'll define three points in time:\n",
    "\n",
    "* `t0` is when the tumor formed (soon I'll be more precise about what that means).\n",
    "\n",
    "* `t1` is when my correspondent retired.\n",
    "\n",
    "* `t2` is when the tumor was detected.\n",
    "\n",
    "I learned from my correspondent that the time between `t1` and `t2` was 3291 days (about 9 years)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "interval = 3291      # days"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As an example, let's assume that the diameter of the tumor at `t1` was 1 cm."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "d1 = 1      # cm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following function computes the volume of a sphere with a given diameter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def calc_vol(diameter):\n",
    "    \"\"\"Converts a diameter to a volume.\n",
    "\n",
    "    V = 4/3 pi (d/2)^3\n",
    "    \"\"\"\n",
    "    factor = 4 * np.pi / 3\n",
    "    return factor * (diameter/2.0)**3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So if we assume that the tumor is spherical, we can compute its volume at `t1`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "v1 = calc_vol(d1)\n",
    "v1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The median volume doubling time reported by Zhang et al. is 811 days."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "median_doubling_time = 811       # days"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So we can compute the number of doublings that would have happened in the given interval at the median growth rate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "doublings = interval / median_doubling_time\n",
    "doublings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Given `v1` and the number of doublings, we can compute the volume at `t2`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "v2 = v1 * 2**doublings\n",
    "v2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following function computes the diameter of a sphere with the given volume."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_diameter(volume):\n",
    "    \"\"\"Converts a volume to a diameter.\n",
    "\n",
    "    d = 2r = 2 * (3/4/pi V)^1/3\n",
    "    \"\"\"\n",
    "    factor = 3 / np.pi / 4\n",
    "    return 2 * (factor * volume)**(1/3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So we can compute the diameter of the tumor at `t2`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "d2 = calc_diameter(v2)\n",
    "d2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If the diameter of the tumor was 1 cm at `t1`, and it grew at the median rate, the diameter would be about 2.6 cm at `t2`.\n",
    "\n",
    "This example demonstrates the growth model, but it doesn't answer the question my correspondent posed."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Working Backwards\n",
    "\n",
    "We can get a partial answer by starting at the end and working backwards; that is, given that the diameter of the tumor was 15.5 cm at `t2`, how big would it have been at `t1`, assuming that it grew at the median rate?\n",
    "\n",
    "Here's the volume at `t2`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "d2 = 15.5\n",
    "v2 = calc_vol(d2)\n",
    "v2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since we already know the number of doublings in the interval, we can compute the volume at `t1` like this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "v1 = v2 / 2**doublings\n",
    "v1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And given `v1`, we can compute the corresponding diameter:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "d1 = calc_diameter(v1)\n",
    "d1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The diameter at `t1` would have been about 6 cm.\n",
    "We can conclude:\n",
    "\n",
    "* If the tumor grew at the median rate, it must have formed prior to `t1`, or\n",
    "\n",
    "* If it formed after `t1`, it must have grown substantially faster than the median rate.\n",
    "\n",
    "Based on these results, I concluded that is \"more likely than not\" that the tumor formed prior to the date of discharge, and on behalf of my correspondent, I wrote a letter to the Veterans' Benefit Administration.\n",
    "\n",
    "Later I told a friend, who is an oncologist, about my results. \n",
    "He was surprised by the growth rates I found and by what they imply about the ages of these tumors. \n",
    "He suggested that the results might be interesting to researchers and doctors.\n",
    "\n",
    "But in order to make them useful, I needed a more general model of the\n",
    "relationship between age and size."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A More General Model\n",
    "\n",
    "Given the size of a tumor at time of diagnosis, we would like to know the distribution of its age.\n",
    "\n",
    "To find it, we'll run simulations of tumor growth to get the distribution of size conditioned on age. \n",
    "Then we'll use a Bayesian approach to get the distribution of age conditioned on size.\n",
    "\n",
    "The simulation starts with a small tumor and runs these steps:\n",
    "\n",
    "1.  Choose a value from the distribution of growth rates.\n",
    "\n",
    "2.  Compute the size of the tumor at the end of an interval.\n",
    "\n",
    "3.  Repeat until the tumor exceeds the maximum relevant size.\n",
    "\n",
    "So the first thing we need is the distribution of growth rates."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Distribution of Growth Rates\n",
    "\n",
    "Using the figures in the paper by Zhange et al., I created an array, `rdt_sample`, that contains estimated values of RDT for the 53 patients in the study.\n",
    "\n",
    "Again, RDT stands for \"reciprocal doubling time\", which is in doublings per year.\n",
    "So if `rdt=1`, a tumor would double in volume in one year.\n",
    "If `rdt=2`, it would double twice; that is, the volume would quadruple.\n",
    "And if `rdt=-1`, it would halve in volume."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Data from the histogram in Figure 3\n",
    "\n",
    "import numpy as np\n",
    "from empiricaldist import Pmf\n",
    "\n",
    "counts = [2, 29, 11, 6, 3, 1, 1]\n",
    "rdts = np.arange(-1, 6) + 0.01\n",
    "pmf_rdt = Pmf(counts, rdts)\n",
    "pmf_rdt.normalize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Data from the scatter plot in Figure 4\n",
    "\n",
    "rdts = [5.089,  3.572,  3.242,  2.642,  1.982,  1.847,  1.908,  1.798,\n",
    "        1.798,  1.761,  2.703, -0.416,  0.024,  0.869,  0.746,  0.257,\n",
    "        0.269,  0.086,  0.086,  1.321,  1.052,  1.076,  0.758,  0.587,\n",
    "        0.367,  0.416,  0.073,  0.538,  0.281,  0.122, -0.869, -1.431,\n",
    "        0.012,  0.037, -0.135,  0.122,  0.208,  0.245,  0.404,  0.648,\n",
    "        0.673,  0.673,  0.563,  0.391,  0.049,  0.538,  0.514,  0.404,\n",
    "        0.404,  0.33,  -0.061,  0.538,  0.306]\n",
    "\n",
    "rdt_sample = np.array(rdts)\n",
    "len(rdt_sample)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can use the sample of RDTs to estimate the PDF of the distribution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import kde_from_sample\n",
    "\n",
    "qs = np.linspace(-2, 6, num=201)\n",
    "kde_rdt = kde_from_sample(rdt_sample, qs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "1 / kde_rdt.median() * 365"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`kde_rdt` is a `Pmf` object; we can use it to estimate the CDF of the distribution, too."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "cdf_rdt = kde_rdt.make_cdf()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here's what it looks like."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from utils import decorate\n",
    "\n",
    "cdf_rdt.plot(label='rdts')\n",
    "\n",
    "decorate(xlabel='Reciprocal doubling time (RDT)',\n",
    "         ylabel='CDF')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To generate a random value from the distribution, we can use `Pmf.choice`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "np.random.seed(18)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "kde_rdt.choice()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To generate a sequence of random values, I'll use the following generator function.\n",
    "If you are not familiar with generator functions in Python, you can [read about them here](https://wiki.python.org/moin/Generators).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def uncorrelated_generator(pmf, rho=None):\n",
    "    \"\"\"Generates a sequence of values from pmf.\n",
    "\n",
    "    pmf: distribution to choose from\n",
    "    rho: ignored\n",
    "    \"\"\"\n",
    "    while True:\n",
    "        yield pmf.choice()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the current version of the model, using a generator function isn't really necessary, but for the next version it will turn out to be convenient.\n",
    "\n",
    "When we call `uncorrelated_generator`, it returns a generator object:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "rdt_gen = uncorrelated_generator(kde_rdt)\n",
    "rdt_gen"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The generator behaves like a iterator, so we can use it in a `for` loop, or we can use `next` to get the next value.\n",
    "\n",
    "For example, here's a function that takes a generator and generates a sample with the given number of values:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_sample(gen, size=1000):\n",
    "    \"\"\"Get a sample from a generator.\n",
    "    \n",
    "    gen: generator\n",
    "    size: sample size\n",
    "    \n",
    "    returns: list\n",
    "    \"\"\"\n",
    "    return [next(gen) for _ in range(size)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And we can call it like this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample = generate_sample(rdt_gen)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "Here's a quick test to confirm that it works:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from empiricaldist import Cdf\n",
    "\n",
    "cdf_sample = Cdf.from_seq(sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "cdf_rdt.plot(label='model', color='C5')\n",
    "cdf_sample.plot(label='random sample')\n",
    "\n",
    "decorate(xlabel='Reciprocal doubling time (RDT)',\n",
    "         ylabel='CDF')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With that, we have everything we need to simulate the growth of a tumor."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Simulation\n",
    "\n",
    "For the initial diameter I chose 0.3 cm, because carcinomas smaller than that are less likely to be invasive and less likely to have the blood supply needed for rapid growth (see [this page on carcinoma](http://en.wikipedia.org/wiki/Carcinoma_in_situ)).\n",
    "\n",
    "I chose an interval of 245 days (about 8 months) because that is the\n",
    "median time between measurements in the data source.\n",
    "\n",
    "For the maximum diameter I chose 20 cm. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "interval = 245 / 365      # year\n",
    "min_diameter = 0.3        # cm\n",
    "max_diameter = 20         # cm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the data source, the range of observed sizes is 1.0 to 12.0 cm, so we are extrapolating beyond the observed range at each end, but not by far.\n",
    "\n",
    "I'll use `calc_vol` to compute the initial and maximum volumes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "v0 = calc_vol(min_diameter)\n",
    "vmax = calc_vol(max_diameter)\n",
    "v0, vmax"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following function runs the simulation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def simulate_growth(rdt_gen):\n",
    "    \"\"\"Simulate the growth of a tumor.\n",
    "    \n",
    "    rdt_gen: generator that yields RDT\n",
    "    \n",
    "    returns: DataFrame\n",
    "    \"\"\"\n",
    "    age = 0\n",
    "    volume = v0\n",
    "    res = []\n",
    "    \n",
    "    for rdt in rdt_gen:\n",
    "        res.append((age, volume))\n",
    "        if volume > vmax:\n",
    "            break\n",
    "\n",
    "        age += interval \n",
    "        doublings = rdt * interval\n",
    "        volume *= 2**doublings\n",
    "        \n",
    "    columns = ['age', 'volume']\n",
    "    sim = pd.DataFrame(res, columns=columns)\n",
    "    sim['diameter'] = calc_diameter(sim['volume'])\n",
    "    return sim"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`simulate_growth` takes as a parameter a generator that yields reciprocal doubling times (RDT).\n",
    "\n",
    "It initializes the age and volume of the tumor, then runs a loop that simulates one interval at a time.\n",
    "\n",
    "Each time through the loop, it checks the volume of the tumor and exits when it exceeds `vmax`.\n",
    "\n",
    "Then it updates `age` and `volume`.  Since `rdt` is in doublings per year, we multiply by `interval` to get compute the number of doublings during each interval.\n",
    "\n",
    "At the end of the loop, `simulate_growth` puts the results in a `DataFrame` and computes the diameter that corresponds to each volume.\n",
    "\n",
    "Here's how we call this function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "np.random.seed(17)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "rdt_gen = uncorrelated_generator(kde_rdt)\n",
    "sim = simulate_growth(rdt_gen)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here are the results for the first few intervals:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "sim.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And the last few intervals."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "sim.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The simulation is based on the assumption that the growth rate is\n",
    "chosen independently during each interval, so it does not depend on age, size, or growth rate during previous intervals.\n",
    "\n",
    "In Section xxx I review these assumptions and consider more detailed models. \n",
    "But first let's look at some examples.\n",
    "To show the results graphically, I'll run 101 simulations:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "np.random.seed(17)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "rdt_gen = uncorrelated_generator(kde_rdt)\n",
    "sims = [simulate_growth(rdt_gen) for _ in range(101)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And plot the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "diameters = [4, 8, 16]\n",
    "for diameter in diameters:\n",
    "    plt.axhline(diameter,\n",
    "                color='C5', linewidth=2, linestyle='dotted')\n",
    "\n",
    "for sim in sims:\n",
    "    plt.plot(sim['age'], sim['diameter'],\n",
    "             color='C0', linewidth=0.5, alpha=0.5)\n",
    "    \n",
    "decorate(xlabel='Tumor age (years)',\n",
    "         ylabel='Diameter (cm, log scale)',\n",
    "         ylim=[0.2, 20],\n",
    "         yscale='log')\n",
    "\n",
    "yticks = [0.2, 0.5, 1, 2, 5, 10, 20]\n",
    "plt.yticks(yticks, yticks);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this figure, each thin, solid line shows the simulated growth of a tumor over time, with diameter on a log scale.\n",
    "The dotted lines are at 4, 8, and 16 cm.\n",
    "\n",
    "By reading across the dotted lines, you can get a sense of the distribution of age at each size.\n",
    "For example, reading across the top line, we see that a 16 cm tumor might be as young as 10 years or as old as 40 years, but it is most likely to be between 15 and 30.\n",
    "\n",
    "To compute this distribution more precisely, we can interpolate the growth curves to see when each one passes through a given size.\n",
    "The following function takes the results of the simulations and returns the age when each tumor reached a given diameter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.interpolate import interp1d\n",
    "from empiricaldist import Pmf\n",
    "\n",
    "def interpolate_ages(sims, diameter):\n",
    "    \"\"\"Interpolate the age when each tumor reached a given size.\n",
    "    \n",
    "    sims: sequence of DataFrames\n",
    "    diameter: float\n",
    "    \n",
    "    returns: list of ages\n",
    "    \"\"\"\n",
    "    ages = []\n",
    "    for sim in sims:\n",
    "        interp = interp1d(sim['diameter'], sim['age'])\n",
    "        age = interp(diameter)\n",
    "        ages.append(float(age))\n",
    "    return ages"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following figure shows the distribution of ages for tumors with diameters 4, 8, and 16 cm."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "for diameter in diameters:\n",
    "    ages = interpolate_ages(sims, diameter)\n",
    "    cdf = Cdf.from_seq(ages)\n",
    "    cdf.plot(label=f'{diameter} cm')\n",
    "    \n",
    "decorate(xlabel='Tumor age (years)',\n",
    "         ylabel='CDF')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For a tumor 16 cm in diameter, the median age is about 21 years; the 90% credible interval is between 13 and 34 years."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(cdf.median(), cdf.credible_interval(0.9))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These results are consistent with the simple model; it is unlikely that a tumor of this size is less than 9 years old."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Serial Correlation\n",
    "\n",
    "The results so far are based on a number of modeling decisions; let's\n",
    "review them and consider which ones are the most likely sources of\n",
    "error:\n",
    "\n",
    "* To convert from linear measure to volume, we assume that tumors are approximately spherical. This assumption is probably fine for tumors up to a few centimeters, but not for very large tumors.\n",
    "\n",
    "* The distribution of growth rates is estimated on the basis of only 53 patients. A larger sample might yield a different distribution.\n",
    "\n",
    "* The growth model does not take into account tumor subtype or grade; this assumption is consistent with the findings of Zhang et al; they conclude: \"Growth rates in renal tumors of different sizes, subtypes and grades represent a wide range and overlap substantially.\" But with a larger sample, a difference might become apparent.\n",
    "\n",
    "* The distribution of growth rate does not depend on the size of the tumor. This assumption would not be realistic for very small and very large tumors, whose growth is limited by blood supply. But tumors observed by Zhang et al ranged from 1 to 12 cm, and they found no statistically significant relationship between size and growth rate. So if there is a relationship, it is likely to be weak, at least in this size range.\n",
    "\n",
    "* In the simulations, growth rate during each interval is independent of previous growth rates. In reality it is plausible that tumors that have grown quickly in the past are likely to grow quickly in the future. In other words, there is probably a serial correlation in growth rate.\n",
    "\n",
    "Of these, the first and last might be the most problematic. I'll investigate serial correlation first, then come back to spherical geometry.\n",
    "\n",
    "In the next section, we'll modify the simulations to include serial correlation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Correlated Growth\n",
    "\n",
    "To simulate correlated growth, we need to generate random numbers from a given distribution with a given serial correlation.\n",
    "\n",
    "Here's how we can do that:\n",
    "\n",
    "1. First we generate correlated values from a Gaussian distribution. This is easy to do because we can compute the distribution of each value conditioned on the previous value.\n",
    "\n",
    "2. Then we transform each value to its cumulative probability using the Gaussian CDF.\n",
    "\n",
    "3. Finally, we transform each cumulative probability to the corresponding value using the given `Cdf`.\n",
    "\n",
    "The following function computes Steps 2 and 3.\n",
    "It takes `z`, which is a value from a standard normal distribution (with mean 0 and standard deviation 1) and a `Cdf`.\n",
    "\n",
    "It uses the `norm` object from SciPy to compute `p`, which is the cumulative probability of `z` in the normal distribution.\n",
    "\n",
    "Then it uses `Cdf.inverse` to find the quantity in `cdf` that corresponds to `p`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import norm\n",
    "\n",
    "def transform(z, cdf):\n",
    "    \"\"\"Map a standard normal variate to a CDF.\n",
    "    \n",
    "    z: value from a standard normal distribution\n",
    "    cdf: Cdf object\n",
    "    \n",
    "    returns: value from cdf\n",
    "    \"\"\"\n",
    "    p = norm.cdf(z)\n",
    "    y = cdf.inverse(p)\n",
    "    return float(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here's an example that uses `transform` to compute the RDT that corresponds to the value 1 in a standard normal distribution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform(1, cdf_rdt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we pass to `transform` a series of values drawn from a standard normal distribution, the values we get back are drawn from `cdf`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now for Step 1.  To generate values with a given serial correlation, $\\rho$, we start by generating a single value from a standard normal distribution, which I'll call $x$.\n",
    "\n",
    "Given $x$ and $\\rho$, the next value in the series is drawn from a normal distribution with mean $\\rho x$ and standard deviation $\\sqrt{1 - \\rho^2}$.\n",
    "\n",
    "Then each successive value depends on the previous one in the same way.\n",
    "\n",
    "The following is a generator function that implements this algorithm."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "def correlated_generator(cdf, rho):\n",
    "    \"\"\"Generate correlated values from cdf.\n",
    "    \n",
    "    cdf: Cdf object\n",
    "    rho: float -1 to 1\n",
    "    \"\"\"\n",
    "    x = np.random.normal(0, 1)\n",
    "    yield transform(x, cdf)\n",
    "\n",
    "    sigma = np.sqrt(1 - rho**2);    \n",
    "    while True:\n",
    "        x = np.random.normal(rho*x, sigma)\n",
    "        yield transform(x, cdf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here's an example that generates 1000 values from `cdf_rdt` with `rho=0.5`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "np.random.seed(18)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "rdt_gen = correlated_generator(cdf_rdt, 0.5)\n",
    "sample = generate_sample(rdt_gen)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can use `np.corrcoeff` to confirm that we got the correlation we wanted."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.corrcoef(sample[1:], sample[:-1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The results vary from sample to sample, but they are generally near 0.5."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "We can also check that the distribution of the values follows `cdf_rdt`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "cdf_sample = Cdf.from_seq(sample)\n",
    "\n",
    "cdf_rdt.plot(label='model', color='C5')\n",
    "cdf_sample.plot(label='random sample', color='C0')\n",
    "\n",
    "decorate(xlabel='Reciprocal doubling time (RDT)',\n",
    "         ylabel='CDF')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Simulation with Correlation\n",
    "\n",
    "Recall that `simulate_growth` takes a generator as an argument, so it is easy to run the simulations with the correlated generator."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "np.random.seed(22)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "rdt_gen = correlated_generator(cdf_rdt, 0.5)\n",
    "sims2 = [simulate_growth(rdt_gen)\n",
    "         for _ in range(101)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And we can use `interpolate_ages` to extract the distribution of ages for a tumor with a diameter of 16 cm."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "diameter = 16\n",
    "ages = interpolate_ages(sims, diameter)\n",
    "cdf = Cdf.from_seq(ages)\n",
    "    \n",
    "ages2 = interpolate_ages(sims2, diameter)\n",
    "cdf2 = Cdf.from_seq(ages2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following figure shows the distribution of ages with $\\rho=0$ and $\\rho=0.5$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "cdf.plot(label='rho=0')\n",
    "cdf2.plot(label='rho=0.5')\n",
    "    \n",
    "decorate(xlabel='Tumor age (years)',\n",
    "         ylabel='CDF')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Correlation makes the fastest growing tumors faster and the slowest\n",
    "slower, so the range of ages is wider.\n",
    "The following table shows the differences between these distributions for several percentiles."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "ps = np.array([0.05, 0.25, 0.5, 0.75, 0.95])\n",
    "df = pd.DataFrame(columns=ps*100)\n",
    "df.columns.name = 'Percentiles'\n",
    "df.index.name = 'Correlation'\n",
    "\n",
    "df.loc[0] = cdf.quantile(ps)\n",
    "df.loc[0.5] = cdf2.quantile(ps)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The difference is modest for low\n",
    "percentiles, but for the 95th percentile it is more than 8 years. \n",
    "\n",
    "These differences show that serial correlation has a substantial effect on the results.\n",
    "So if we need to compute these distribution precisely, we would need a better estimate of the actual serial correlation.\n",
    "\n",
    "However, this model is sufficient to answer the question we started\n",
    "with: given a tumor with a linear dimension of 15.5 cm, what is the\n",
    "probability that it formed more than 9 years ago?\n",
    "\n",
    "With no serial correlation, the probability is roughly 99.9%, or almost certain. \n",
    "With correlation 0.5, faster-growing tumors are more likely, but the probability is still about 99%.\n",
    "\n",
    "Another likely source of error is the assumption that tumors are\n",
    "approximately spherical. For a tumor with linear dimensions 15.5 x 15\n",
    "cm, this assumption is probably not valid. If, as seems likely, a tumor this size is relatively flat, it might have the same volume as a 6 cm sphere. \n",
    "With this smaller volume and correlation 0.5, the probability the age of the tumor is greater than 9 years is still 95%.\n",
    "\n",
    "So even taking into account modeling errors, it is unlikely that such a large tumor could have formed less than 9 years prior to the date of\n",
    "diagnosis."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Approximate Bayesian Calculation\n",
    "\n",
    "At this point you might wonder why this example is in a book about Bayesian statistics.\n",
    "We never defined a prior distribution or did a Bayesian update.\n",
    "Why not?\n",
    "\n",
    "Because we didn't have to.\n",
    "Instead we used simulations to compute ages and sizes for a collection of hypothetical tumors.\n",
    "Then, implicitly, we used the simulation results to form a joint distribution of age and size.\n",
    "\n",
    "If we select a column from the joint distribution, we get a distribution of size conditioned on age.\n",
    "If we select a row, we get a distribution of age conditioned on size.\n",
    "\n",
    "So this example is like the ones we saw in Chapter 1xxx: if you have all of the data, you don't need Bayes's theorem; you can compute probabilities by counting.\n",
    "\n",
    "This example is a first step toward Approximate Bayesian Computation (ABC).\n",
    "The next example is a second step."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Counting Cells\n",
    "\n",
    "This example comes from Cameron Davidson-Pilon, who also provided the Space Shuttle problem in Chapter xxx.\n",
    "\n",
    "In [this blog post](https://dataorigami.net/blogs/napkin-folding/bayesian-cell-counting), Davidson-Pilon models the process biologists use to estimate the concentration of cells, or other discrete elements, in a sample of liquid.\n",
    "\n",
    "The example he presents is counting cells in a \"yeast slurry\", which is a mixture of yeast and water used in brewing beer.\n",
    "\n",
    "There are two steps in the process:\n",
    "\n",
    "* First, the slurry is diluted until the concentration is low enough that it is practical to count cells.\n",
    "\n",
    "* Then a small sample is put on a hemocytometer, which is a specialized microscope slide that holds a fixed amount of liquid on a rectangular grid etched in the glass.\n",
    "\n",
    "The cells and the grid are visible in a microscope, making it easy to count the cells accurately.\n",
    "\n",
    "As an example, suppose we start with a yeast slurry with unknown concentration of cells.\n",
    "\n",
    "Starting with a 1 mL sample, we dilute it by adding it to a shaker with 9 mL of water and mixing well.\n",
    "Then we dilute it again, and then a third time.\n",
    "Each dilution reduces the concentration by a factor of 10, so three dilutions reduces the concentration by a factor of 1000.\n",
    "\n",
    "Then we add the diluted sample to the hemocytometer, which has a capacity of 0.0001 mL spread over a 5x5 grid.\n",
    "\n",
    "Although the grid has 25 squares, it is standard practice to inspect only a few of them, say 5, and report the total number of cells in the inspected squares.\n",
    "\n",
    "This process is simple enough, but at every stage there are sources of error:\n",
    "\n",
    "* During the dilution process, liquids are measured using pipettes that introduce measurement error.\n",
    "\n",
    "* The amount of liquid in the hemocytometer might vary from the specification.\n",
    "\n",
    "* During each step of the sampling process, we might select more or less than the average number of cells, due to random variation.\n",
    "\n",
    "Davidson-Pilon presents a PyMC model that describes these errors.\n",
    "I'll start by replicating his model; then we'll adapt it for ABC."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Suppose there are 25 squares in the grid, we count 5 of them, and the total number of cells is 49."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_squares = 25\n",
    "squares_counted = 5\n",
    "yeast_counted = 49"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here's the first part of the model, which defines the prior distribution of `yeast_conc`, which is the concentration of yeast we're trying to estimate.\n",
    "\n",
    "`shaker1_vol` is the actual volume of water in the first shaker, which should be 9 mL, but might be higher or lower, with standard deviation 0.05 mL.\n",
    "\n",
    "`shaker2_vol` and `shaker3_vol` are the volumes in the second and third shakers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pymc3 as pm\n",
    "billion = 1e9\n",
    "\n",
    "with pm.Model() as model:\n",
    "    yeast_conc = pm.Normal(\"yeast conc\", \n",
    "                           mu=2 * billion, sd=0.4 * billion)\n",
    "\n",
    "    shaker1_vol = pm.Normal(\"shaker1 vol\", \n",
    "                               mu=9.0, sd=0.05)\n",
    "    shaker2_vol = pm.Normal(\"shaker2 vol\", \n",
    "                               mu=9.0, sd=0.05)\n",
    "    shaker3_vol = pm.Normal(\"shaker3 vol\", \n",
    "                               mu=9.0, sd=0.05)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, the sample we draw from the yeast slurry is supposed to be 1 mL, but might be more or less.\n",
    "And similarly for the sample we draw from the first shaker and from the second shaker.\n",
    "\n",
    "The following variables model these samples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "with model:\n",
    "    yeast_slurry_vol = pm.Normal(\"yeast slurry vol\",\n",
    "                                    mu=1.0, sd=0.01)\n",
    "    shaker1_to_shaker2_vol = pm.Normal(\"shaker1 to shaker2\",\n",
    "                                    mu=1.0, sd=0.01)\n",
    "    shaker2_to_shaker3_vol = pm.Normal(\"shaker2 to shaker3\",\n",
    "                                    mu=1.0, sd=0.01)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Given the actual volumes in the samples and in the shakers, we can compute the effective dilution, `final_dilution`, which should be approximately 1000, but might be higher or lower."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "with model:\n",
    "    dilution_shaker1 = (yeast_slurry_vol       / \n",
    "                        (yeast_slurry_vol + shaker1_vol))\n",
    "    dilution_shaker2 = (shaker1_to_shaker2_vol / \n",
    "                        (shaker1_to_shaker2_vol + shaker2_vol))\n",
    "    dilution_shaker3 = (shaker2_to_shaker3_vol / \n",
    "                        (shaker2_to_shaker3_vol + shaker3_vol))\n",
    "    \n",
    "    final_dilution = (dilution_shaker1 * \n",
    "                      dilution_shaker2 * \n",
    "                      dilution_shaker3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The next step is to place a sample from the third shaker in the chamber of the hemocytomer.\n",
    "The capacity of the chamber should be 0.0001 mL, but might vary; to describe this variance, we'll use a gamma distribution, which ensures that we don't generate negative values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "with model:\n",
    "    chamber_vol = pm.Gamma(\"chamber_vol\", \n",
    "                           mu=0.0001, sd=0.0001 / 20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On average, the number of cells in the chamber is the product of the actual concentration, final dilution, and chamber volume.\n",
    "But the actual number might vary; we'll use a Poisson distribution to model this variance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "with model:\n",
    "    yeast_in_chamber = pm.Poisson(\"yeast in chamber\", \n",
    "        mu=yeast_conc * final_dilution * chamber_vol)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, each cell in the chamber will be in one of the squares we count with probability `p=squares_counted/total_squares`.\n",
    "So the actual count follows a binomial distribution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "with model:\n",
    "    count = pm.Binomial(\"count\", \n",
    "        n=yeast_in_chamber, \n",
    "        p=squares_counted/total_squares,\n",
    "        observed=yeast_counted)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With the model specified, we can use `sample` to generate a sample from the posterior distribution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "with model:\n",
    "    trace = pm.sample(1000, return_inferencedata=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And we can use the sample to estimate the posterior distribution of `yeast_conc` and compute summary statistics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "posterior_sample = trace['yeast conc'] / billion\n",
    "cdf_pymc = Cdf.from_seq(posterior_sample)\n",
    "print(cdf_pymc.mean(), cdf_pymc.credible_interval(0.9))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So far we've been following in Davidson-Pilon's steps.\n",
    "And for this problem, the solution using MCMC is sufficient.\n",
    "But it also provides an opportunity to demonstrate ABC."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cell counting with ABC\n",
    "\n",
    "The fundamental idea of ABC is that we use the prior distribution to generate a sample of the parameters, and then simulate the system for each set of parameters in the sample.\n",
    "\n",
    "In this case, since we already have a PyMC model, we can use `sample_prior_predictive` to do the sampling and the simulation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "with model:\n",
    "    prior_sample = pm.sample_prior_predictive(10000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The result is a dictionary that contains samples from the prior distribution of the parameters and the prior predictive distribution of count."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "count = prior_sample['count']\n",
    "print(count.mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, to generate a sample from the posterior distribution, we'll select only the elements in the prior sample where the output of the simulation, `count`, matches the observed data, 49."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask = (count == 49)\n",
    "mask.sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we select only the samples that yield the observed data, the result is a sample from the posterior distribution of the parameters.\n",
    "In this example, the parameter we are most interested in is the yeast concentration.\n",
    "\n",
    "We can use `mask` to select the values of `yeast_conc` for the simulations that yield the observed data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "posterior_sample2 = prior_sample['yeast conc'][mask] / billion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And we can use the posterior sample to estimate the CDF of the posterior distribution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "cdf_abc = Cdf.from_seq(posterior_sample2)\n",
    "print(cdf_abc.mean(), \n",
    "      cdf_abc.credible_interval(0.9))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The posterior mean and credible interval are similar to what we got with MCMC.\n",
    "Here's what the distributions look like."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "cdf_pymc.plot(label='MCMC')\n",
    "cdf_abc.plot(label='ABC')\n",
    "\n",
    "decorate(xlabel='Yeast concentration (cells/mL)',\n",
    "         ylabel='CDF',\n",
    "         title='Posterior distribution',\n",
    "         xlim=(1.4, 3.4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The distributions are similar, but the results from ABC are noisier because the sample size is smaller."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## When do we get to the approximate part?\n",
    "\n",
    "The examples so far are similar to Approximate Bayesian Computation, but neither of them demonstrates all of the elements of ABC.\n",
    "\n",
    "More generally, ABC is characterized by:\n",
    "\n",
    "1. A prior distribution of parameters.\n",
    "\n",
    "2. A simulation of the system that generates the data.\n",
    "\n",
    "3. A criterion for when we should accept that the output of the simulation matches the data.\n",
    "\n",
    "The kidney tumor example was atypical because we didn't represent the prior distribution of age explicitly.\n",
    "Because the simulations generate a joint distribution of age and size, we we able to get the marginal posterior distribution of age directly from the results.\n",
    "\n",
    "The yeast example is more typical because we represented the distribution of the parameters explicitly.\n",
    "But we accepted only simulations where the output matches the data exactly.\n",
    "\n",
    "The result is approximate in the sense that we have a sample from the posterior distribution rather than the posterior distribution itself.\n",
    "But it is not approximate in the sense of Approximate Bayesian Computation, which often accepts simulations where the output matches the data only approximately."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To show how that works, I will extend the yeast example with an approximate matching criterion.\n",
    "\n",
    "In the previous section, we accepted a simulation if the output is precisely 49 and rejected it otherwise.\n",
    "As a result, we got only a few hundred samples out of 10,000 simulations, so that's not very efficient.\n",
    "\n",
    "We can make better use of the simulations if we give \"partial credit\" when the output is close to 49.\n",
    "But how close?  And how much credit?\n",
    "\n",
    "One way to answer that is to back up to the second-to-last step of the simulation, where we know the number of cells in the chamber, and we use the binomial distribution to generate the final count.\n",
    "\n",
    "If there are `n` cells in the chamber, each has a probability `p` of being counted, depending on whether it falls in one of the squares in the grid that get counted.\n",
    "\n",
    "We can extract `n` from the prior sample, like this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = prior_sample['yeast in chamber']\n",
    "n.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And compute `p` like this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "p = squares_counted/total_squares\n",
    "p"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now here's the idea: we'll use the binomial distribution to compute the likelihood of the data, `yeast_counted`, for each value of `n` and the fixed value of `p`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import binom\n",
    "\n",
    "likelihood = binom(n, p).pmf(yeast_counted).flatten()\n",
    "likelihood.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When the expected count, `n * p`, is close to the actual count, `likelihood` is relatively high; when it is farther away, `likelihood` is lower.\n",
    "\n",
    "The following is a scatter plot of these likelihoods versus the expected counts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "plt.plot(n*p, likelihood, '.', alpha=0.1)\n",
    "\n",
    "decorate(xlabel='Expected count (number of cells)',\n",
    "         ylabel='Likelihood')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can't use these likelihoods to do a Bayesian update because they are incomplete; that is, each likelihood is the probability of the data given `n`, which is the result of a single simulation.\n",
    "\n",
    "But we *can* use them to weight the results of the simulations.\n",
    "Instead of requiring the output of the simulation to match the data exactly, we'll use the likelihoods to give partial credit when the output is close.\n",
    "\n",
    "Here's how: I'll construct a `Pmf` that contains yeast concentrations as quantities and the likelihoods as unnormalized probabilities."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "qs = prior_sample['yeast conc'] / billion\n",
    "ps = likelihood\n",
    "posterior_pmf = Pmf(ps, qs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this `Pmf`, values of `yeast_conc` that yield outputs close to the data map to higher probabilities.\n",
    "\n",
    "If we sort the quantities and normalize the probabilities, the result is an estimate of the posterior distribution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "posterior_pmf.sort_index(inplace=True)\n",
    "posterior_pmf.normalize()\n",
    "\n",
    "print(posterior_pmf.mean(), posterior_pmf.credible_interval(0.9)) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The posterior mean and credible interval are similar to the values we got from MCMC.\n",
    "\n",
    "And here's what the posterior distributions look like."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "cdf_pymc.plot(label='MCMC')\n",
    "#cdf_abc.plot(label='ABC')\n",
    "posterior_pmf.make_cdf().plot(label='ABC2')\n",
    "\n",
    "decorate(xlabel='Yeast concentration (cells/mL)',\n",
    "         ylabel='CDF',\n",
    "         title='Posterior distribution',\n",
    "         xlim=(1.4, 3.4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The distributions are similar, but the results from MCMC are a little noisier.\n",
    "In this example, ABC is more efficient than MCMC, requiring less computation to generate a better estimate of the posterior distribution.\n",
    "\n",
    "But that's unusual; usually ABC requires a lot of computation.\n",
    "For that reason, it is generally a method of last resort."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "In this chapter we saw two examples of Approximate Bayesian Computation (ABC), based on simulations of tumor growth and cell counting.\n",
    "\n",
    "The definitive elements of ABC are:\n",
    "\n",
    "1. A prior distribution of parameters.\n",
    "\n",
    "2. A simulation of the system that generates the data.\n",
    "\n",
    "3. A criterion for when we should accept that the output of the simulation matches the data.\n",
    "\n",
    "ABC is particularly useful when the system is too complex to model with tools like PyMC.\n",
    "For example, it might involve a physical simulation based on differential equations.\n",
    "In that case, each simulation might require substantial computation, and many simulations might be needed to estimate the posterior distribution.\n",
    "\n",
    "In the next section, you'll have a chance to practice with one more example."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercises"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise:** This exercise is based on [a blog post by Rasmus Bååth](http://www.sumsar.net/blog/2014/10/tiny-data-and-the-socks-of-karl-broman), which is motivated by a tweet from Karl Broman, who wrote:\n",
    "\n",
    "> That the first 11 socks in the laundry are distinct suggests that there are a lot of socks.\n",
    "\n",
    "Suppose you pull 11 socks out of the laundry and find that no two of them make a matched pair.  Estimate the number of socks in the laundry.\n",
    "\n",
    "To solve this problem, we'll use the model Bååth suggests, which is based on these assumptions:\n",
    "\n",
    "* The laundry contains some number of pairs of socks, `n_pairs`, plus some number of unpaired socks, `n_odds`.\n",
    "\n",
    "* The pairs of socks are different from each other and different from the unpaired socks; in other words, the number of socks of each type is either 1 or 2, never more.\n",
    "\n",
    "We'll also use the prior distributions Bååth suggests, which are:\n",
    "\n",
    "* The number of socks follow a negative binomial distribution with mean 30 and standard deviation 15.\n",
    "\n",
    "* The proportion of socks that are paired follows a beta distribution with parameters `alpha=15` and `beta=2`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "To get you started, I'll define the priors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from scipy.stats import nbinom, beta\n",
    "\n",
    "mu = 30\n",
    "p = 0.8666666\n",
    "r = mu * (1-p) / p\n",
    "\n",
    "prior_n_socks = nbinom(r, 1-p)\n",
    "prior_n_socks.mean(), prior_n_socks.std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "prior_prop_pair = beta(15, 2)\n",
    "prior_prop_pair.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "qs = np.arange(90)\n",
    "ps = prior_n_socks.pmf(qs)\n",
    "pmf = Pmf(ps, qs)\n",
    "pmf.normalize()\n",
    "\n",
    "pmf.plot(label='prior', drawstyle='steps')\n",
    "\n",
    "decorate(xlabel='Number of socks',\n",
    "         ylabel='PMF')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from utils import pmf_from_dist\n",
    "\n",
    "qs = np.linspace(0, 1, 101)\n",
    "pmf = pmf_from_dist(prior_prop_pair, qs)\n",
    "pmf.plot(label='prior', color='C1')\n",
    "\n",
    "decorate(xlabel='Proportion of socks in pairs',\n",
    "         ylabel='PDF')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "We can sample from the prior distributions like this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "n_socks = prior_n_socks.rvs()\n",
    "prop_pairs = prior_prop_pair.rvs()\n",
    "\n",
    "n_socks, prop_pairs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "And use the values to compute `n_pairs` and `n_odds`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "n_pairs = np.round(n_socks//2 * prop_pairs)\n",
    "n_odds = n_socks - n_pairs*2\n",
    "\n",
    "n_pairs, n_odds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "Now you can take it from there."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Solution goes here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Solution goes here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Solution goes here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Solution goes here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Solution goes here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Solution goes here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Solution goes here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Solution goes here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Solution goes here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Solution goes here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Solution goes here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "celltoolbar": "Tags",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
